\section{Experimentation and evaluation of the proposal}
\label{sec:experimentation-and-evaluation}

The goal of this section is to present the experiments we have conducted on the divide-and-conquer DR algorithm to assess its quality and performance. Following the methodology described in section \ref{sec:experiment-methodology-parameter-tuning}, we were able to corroborate the space and time complexity of the procedure and understand better it's embedding mechanism. We chose the swiss roll and MNIST datasets for the tests because of their popularity, which makes it easier to compare our method with others in the literature, and because of how well Isomap and t-SNE embedded them. That allowed us to go even further and succesfully unfold a $10^8$ points swiss roll with divide-and-conquer Isomap. On the other hand, the classification task in the MNIST dataset proved more complicated to our algorithm, which was slower and separated digits worse than \verb|openTSNE|'s implementation of t-SNE.

The experimentation and evaluation process also provided us some insights on the standard SMACOF, LMDS, Isomap and t-SNE techniques. For example, we realized that LMDS, a nonlinear method intended to overcome the limitations of the SMACOF algorithm \citep{Chen2009}, was not able to unfold the swiss roll dataset. Even after having tuned the $k$ and $\tau$ parameters (see Algorithm \ref{alg:LMDS}), its embedding was porous and irregular instead of uniform and rectangular (see Figure \ref{fig:LMDS-swiss-roll}). Further research on this problem might lead to the development of a variation of LMDS that reduces the dimensionality of the swiss roll better.

Finally, we will describe the computer system we perfomed the tests on. Even though our main development computer was a  Macbook Pro (14-inc, Nov 2023) with 16 GB of RAM and the Apple M3 chip, we noticed that the \verb|concurrent.futures| module, which parallelized the execution of Algorithm \ref{alg:DivideConquer}, did not work in Mac computers with ARM chipsets. Therefore, we ended up using a Windows system. Specifically, our PC was an Asus ROG G513QM-HF026 laptop with the AMD Ryzen 7 5800H CPU, 16 GB of DDR4-3200MHz RAM, an SSD M.2 NVMe PCIe 3.0 and an NVIDIA RTX 3060 GPU.

\subsection{Initial runtime benchmark}

Isomap was the first DR method we implemented into our divide-and-conquer framework, so it also was the first method we benchmarked. We tested divide-and-conquer Isomap on the swiss roll dataset with different parameter combinations and with parallel and serial computation. However, in all tests the number of connecting points for the Procrustes transformation was 100. We chose this number because, based on the thesis directors' experience on big data MDS \citep{Delicado2024}, it guaranteed good links between partitions' embeddings and efficient computations when $1,000 \leq l \leq 10,000$. Figure \ref{fig:Isomap-benchmark} shows the average runtimes of 20 experiments with different sets of parameters and dataset sizes. Parameters were previously tuned to ensure embeddings would preserve the structure of the data. As described in section \ref{sec:experiment-methodology-parameter-tuning}, we applied bare Isomap to swiss rolls of 1,000, 3,162 and 10,000 points, following a logarithmic sequence. Notice that we increased the number of neighbors $k$ for larger values of $l$ because partitions were denser.

After some experimentatiton, we realized that if $l=3162$ and $k=10$, the embedding was nearly perfect no matter the amount of individuals (see Figure \ref{fig:Isomap-huge}). Meanwhile, when $l=10,000$ and $k=15$, quality was similar and time was significantly larger, so we used $l=3162$ and $k=10$ for the largest datasets. This way, we managed to embed $10^8$ three-dimensional points into the Euclidean plane in about 3 hours. Hence, we showed that divide-and-conquer Isomap is capable of handling arbitrarily large datasets on a standard computer while maintaining the quality of the embedding.

Regarding parallelization, we can observe in Figure \ref{fig:Isomap-benchmark} that it effectively reduces the time complexity of divide-and-conquer DR, although its overhead slows down the algorithm when $n \leq 10^4$. Overall, results show that divide-and-conquer Isomap is linear in time with respect to $n$.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/Isomap-benchmark.png}
    \caption{Runtime (s) of divide-and-conquer Isomap averaged over 20 experiments. Tests were performed on datasets generated on the swiss roll manifold \citep{Spiwokv2007} with sizes ranging from $10^3$ to $10^8$. Data was embedded into $\mathbb{R}^2$ with different parameter combinations and $c=100$. Runtime in parallel and serial execution is also compared.}
    \label{fig:Isomap-benchmark}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/Isomap-huge.png}
    \caption{Bidimensional embedding of a $10^8$ points swiss roll dataset \citep{Spiwokv2007} computed by divide-and-conquer Isomap with $l=3,162, \, c=100$ and $k=10$. Color represents the angle of rotation along the swiss roll spiral.}
    \label{fig:Isomap-huge}
\end{figure}

Afterwards, we tested divide-and-conquer t-SNE on the same datasets (see Figure \ref{fig:t-SNE-benchmark}). However, t-SNE performed notably slower than Isomap on the swiss roll, so we only run its divide-and-conquer variation with one parameter combination, $c = 100, \, l=1,000, \, Perp=30, \, n\_iter=250$. $n\_iter$ is the number of iterations carried out to minimize the Kullback-Leibler divergence \citep{Kullback1951}.

Even though divide-and-conquer t-SNE is about two orders of magnitud slower than divide-and-conquer Isomap, time complexity is linear as well, proving the expected results. The quality of the embedding, on the other hand, is very low. See Figure \ref{fig:t-SNE-huge} to observe that the structure of the data is broken into separate parts and the spiral shape is not unfolded.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/tSNE-benchmark.png}
    \caption{Runtime (s) of divide-and-conquer Isomap and divide-and-conquer t-SNE averaged over 20 experiments. Tests were performed on datasets generated on the swiss roll manifold \citep{Spiwokv2007} with sizes ranging from $10^3$ to $10^8$. Data was embedded into $\mathbb{R}^2$ with different parameter combinations and $c=100$.}
    \label{fig:t-SNE-benchmark}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/t-SNE-swiss-roll-huge.png}
    \caption{Bidimensional embedding of a $10^6$ points swiss roll dataset \citep{Spiwokv2007} computed by divide-and-conquer t-SNE with $l=1,000, \, c=100, \, Perp=30$ and $n\_iter=250$. Color represents the angle of rotation along the swiss roll spiral.}
    \label{fig:t-SNE-huge}
\end{figure}

\subsection{Analysis of possible overheads in divide-and-conquer DR}

One reasonable question to formulate about the divide-and-conquer approach is whether splitting the data and merging the resulting embeddings constitue a significant computational cost in comparison to reducing each partition's dimensionality. Theoretically, fractionating the data should be rapid. As for the merging of partitions' embeddings, in section \ref{sec:specification-and-design-of-the-solution} we depicted how we align and overlap them with Procustes transformations between each embedding and one in specific (the first one). We intentionally find a rigid transformation only with a random subset of $c < l$ points to accelerate its computation, and then multiply the full partition's embedding with the $q\times q$ matrix of the transformation. Therefore, the overhead of merging embeddings should be insignificant.

Table \ref{tab:dc-overhead} shows the results of an experiment where each part of the divide-and-conquer DR algorithm was independently timed. We uniformly sampled 5,000 points from the MNIST dataset and embedded them into the Euclidean plane with divide-and-conquer SMACOF. The arguments used were $l=1000,\, c=100,\, n\_iter = 300,\, \varepsilon = 0.001$. As it was expected, neither partitioning the dataset nor aligning the partial embeddings entail a noteworthy overhead in divide-and-conquer DR. Indeed, the prior and the latter were about 5,506 times and 50,710 times swifter than embedding all partitions with SMACOF, respectively.

\begin{table}[ht]
    \centering
    \begin{tabular}{lccc}
        \toprule
        Operation    & Divide & Embed & Merge \\
        \midrule
        Duration (s) & $6.88 \times 10^{-3}$ & 37.88 & $7.47 \times 10^{-4}$ \\
        \bottomrule
    \end{tabular}
    \caption{Runtime (s) of each step of divide-and-conquer SMACOF on a 5000-point random subset of MNIST. The arguments used were $l=1000,\, c=100,\, n\_iter = 300,\, \varepsilon = 0.001$.}
    \label{tab:dc-overhead}
\end{table}

\subsection{Experiments on SMACOF}

\subsubsection{Swiss roll let's goooooo}

SMACOF is not able to unfold a 3000 points swiss roll. This is what we can extract from Figure \ref{fig:SMACOF-swiss-roll-3000}. With 10,000 points, bare SMACOF crashed. But with 7,500 points the same as with 3000 points happens (see Figure \ref{fig:SMACOF-swiss-roll-7500})

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/SMACOF-swiss-roll-3000.png}
    \caption{SMACOF vs 3000 swiss roll muahahahaha.}
    \label{fig:SMACOF-swiss-roll-3000}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/SMACOF-swiss-roll-7500.png}
    \caption{SMACOF vs 7500 swiss roll muahahahaha.}
    \label{fig:SMACOF-swiss-roll-7500}
\end{figure}

To conclude, even though the SMACOF algorithm is not capable to properly embedd the swiss roll, we can see a clear advantage in using it with our divide-and-conquer approach. Indeed, divide-and-conquer is about 22x faster than the bare method and the embedding obtained is very similar for all number of datapoints. The only visual differences are noisier edges and wider shapes in the divide-and-conquer embedding.

Finally, bare SMACOF is not capable of embedding a 10000 points swiss roll on a system with 16 GB of RAM and takes about 17 min to embed a swiss roll of 75000 points. On the other hand, divide-and-conquer can easily and performantly handle larger datasets.

\subsubsection{MNIST time, COME. ON. !!!}

After trying to run bare SMACOF on the whole partition 1 (with 172518 images) for 12 min, we stopped its execution because no message was being printed (which might mean that the Kernel would eventually crash). Next, we try with a subpartition of 5000 images, since that worked properly with the swiss roll. We tried a few parameter combinations and obtained the best for ... Figure \ref{fig:SMACOF-MNIST-kde} shows it is not bad, although 4, 7 and 9 are expectedly mixed. 5 could also be confused by 2 and 8 and viceversa. All normal here, their shapes are indeed similar.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/SMACOF-MNIST-kde.png}
    \caption{SMACOF vs 5000 MNIST. kde rocks.}
    \label{fig:SMACOF-MNIST-kde}
\end{figure}

Maybe I should talk about dimension correlation between SMACOF and divide-and-conquer SMACOF. The point of this is the framework, not the DR method, you know?

Merda, i falta el temps.


\subsection{LMDS now}

\subsubsection{Oh girl, LMDS is so bad on the swiss roll...}

Consider a swiss roll of 1,000 points. Well, LMDS makes trash out of it. Figure \ref{fig:LMDS-swiss-roll}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/LMDS-swiss-roll.png}
    \caption{LMDS devorant rollito de suís sionista, 1954.}
    \label{fig:LMDS-swiss-roll}
\end{figure}

\subsubsection{What abou MNIST tough? WHAT ABOUT IT???}

Same 5000 points MNIST subset, mate. Oh, but this is very bad... Like, worse than SMACOF HAHAHAHAHA.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/LMDS-MNIST.png}
    \caption{L'LMDS es menja el 4.}
    \label{fig:LMDS-MNIST}
\end{figure}

Parla del temps i la correlació dimensionaaaaaaal.

\subsection{Isomap, the sionist swiss killer queen}

\subsection{Swiss roll}

Aaaaah... I don't have the same here. Gotta get those damn plots. Well we've seen this before, in the initial benchmark. Just go see Figure \ref{fig:Isomap-huge}.

\subsubsection{MNIST}

There you go, Figure \ref{fig:Isomap-MNIST}. It's just so bad HAHAHAHAHAH I can't handle this anymore.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/Isomap-MNIST.png}
    \caption{Isomap, babyyyyyy.}
    \label{fig:Isomap-MNIST}
\end{figure}

\subsection{t-SNE}

\subsection{Swiss roll o, com a mi m'agrada nombrar-lo, volteret suís}

t-SNE is specially useful for visualization, so we will focus on MNIST. Nonetheless, here's the swiss roll. Figure \ref{fig:t-SNE-huge}.

\subsubsection{t-SNE MNIST-TSINM, daddy, daddy, oh -!- ooooooooooh}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/t-SNE-MNIST-5000.png}
    \caption{t-SNE on the numerets, germà gran.}
    \label{fig:t-SNE-MNIST}
\end{figure}

AAAAAAAAra bé, l'original no només és millor; també és més ràpid! Va, mira què passa quan busquem una combinació de paràmetres pel t-SNE que funcioni bé amb 1000 dibuixets de números. Figure \ref{fig:t-SNE-MNIST-dc}. Però és que mira el bare hahahahahahah Figure \ref{fig:t-SNE-MNIST-bare}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/t-SNE-MNIST-dc.png}
    \caption{t-SNE on the tots numerets, germà gran, i dividint i conquerint!}
    \label{fig:t-SNE-MNIST-dc}
\end{figure}

\begin{figure}[ht]
    \centering
    \includegraphics[width=\textwidth]{figures/t-SNE-MNIST-bare.png}
    \caption{t-SNE on the tots numerets, germà gran, openTSNE!}
    \label{fig:t-SNE-MNIST-bare}
\end{figure}

Conclusió: no hem guanyat aquesta batalla perquè la competència és un F1 i el nostre és un turisme. Però oi que no t'emportaries un F1 a la muntanya? Aaaaah-mic!

I ja estaria, xd. Anem bé de pàgines, béeeeeeeee.