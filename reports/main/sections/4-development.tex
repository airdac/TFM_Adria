\section{Development of the Proposal}

\begin{itemize}
    \item DR methods implementations: packages used, problems found during development, tuning of parameters, experiments' methodology
\end{itemize}

\subsection{Python implementation of Divide-and-conquer for DR}

Given that R and Python are the standard programming languages in the Data Science field, we chose them as appropriate to implement the divide-and-conquer for DR algorithm. Initially, we aimed to depelop and publish an R library because the thesis directors already had experience with it. However, after reviewing the literature on DR for Big Data \cite{Reichmann2024}, we realized that many solutions were implemented in Python instead. So, in order to leverage the existing coding ecosystem, we switched to Python.

Our code, then, as well as the whole thesis, was documented on an open-source GitHub repository (\href{https://github.com/airdac/TFM_Adria}{https://github.com/airdac/TFM\_Adria}). This system will also allow us to update and share our implementations and experiments easily.

With time, python modules have been structured in a directory tree as a library. Therefore, even though our project has not been published in any Python package index, it effectively works as a library with specific classes and methods. The main function is \verb|divide_conquer|, which implements Algorithm \ref{alg:DivideConquer} in parallel through the \verb|concurrent.futures| module. \verb|divide_conquer| also depends on private methods and requires a \verb|DRMethod| object as one of its arguments. This class, inherited from \verb|enum.Enum|, lists the supported DR methods in our package, which can be called through the \verb|get_method_function| method.

We have implemented four DR techniques: SMACOF, Local MDS, Isomap and t-SNE. All but Local MDS are wrappers to methods in other Python libraries, which are efficient and parallelized. Specifically, we make us of the \verb|sklearn.manifold| module \cite{Pedregosa2011} for Isomap and SMACOF and \verb|openTSNE| \cite{Poliƒçar2023} for t-SNE. Local MDS, on the other hand, is a less popular method and has no public Python implementation at the moment. However, the R library \verb|smacofx| (\textit{CITAR}) does. Therefore, we translated it to Python and adapted it to our framework. This also allowed us to optimize it with the \verb|numba| jit compitler (\textit{CITAR}).

\subsection{Python Packages Used}

\begin{itemize}
    \item \textbf{In general and for experiments}: \begin{itemize}
        \item numpy
        \item pandas
        \item matplotlib.pyplot
        \item os
        \item time
        \item sys
        \item logging
        \item warnings
        \item typing
        \item shutil
    \end{itemize}
    \item \textbf{In D\&C}: \begin{itemize}
        \item concurrent.futures for parallelization
    \end{itemize}

    \item \textbf{For DR methods}: \begin{itemize}
        \item enum
        \item scipy.spatial.distance
        \item sklearn.manifold.Isomap, sklearn.manifold.smacof
        \item openTSNE.TSNE
        \item numba, sklearn.neighbors and stops (from R translated to Python) for Local MDS
    \end{itemize}
\end{itemize}

\subsection{Experiment's methodology and tuning of parameters}

Experiments' methodology.

Tuning of parameters. A few cases.