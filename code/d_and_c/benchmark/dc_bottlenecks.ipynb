{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "72a5dd98",
   "metadata": {},
   "source": [
    "# divide_conquer() internal benchmark\n",
    "Our goal is to detect possible bottlenecks in divide_conquer()."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e0e524a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/Users/airdac/Documents/Uni/Second/TFM/TFM_Adria/code'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_root = os.path.abspath(os.path.join(os.getcwd(), \"..\", \"..\"))\n",
    "if project_root not in sys.path:\n",
    "    sys.path.insert(0, project_root)\n",
    "project_root"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bc1200d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from concurrent.futures import ProcessPoolExecutor\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "from d_and_c.methods import DRMethod, get_method_function\n",
    "from d_and_c.utils import plot_3D_to_2D\n",
    "from d_and_c.private_d_and_c import perform_procrustes, get_partitions_for_divide_conquer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfe00611",
   "metadata": {},
   "source": [
    "Define divide_conquer and main_divide_conquer but saving timings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1857c0c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _main_divide_conquer_benchmark(args: tuple) -> tuple[np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Process a single partition in the divide and conquer algorithm.\n",
    "\n",
    "    Parameters:\n",
    "        args (tuple) : tuple of the following arguments:\n",
    "        method (DRMethod): Dimensionality reduction method to use\n",
    "        x_filtered (np.ndarray): Data points of the current partition.\n",
    "        x_sample_1 (np.ndarray): Connecting points sampled from the first partition.\n",
    "        r (int): Target dimensionality.\n",
    "        original_sample_1 (np.ndarray): Projection of the anchor points from the first partition.\n",
    "        plot (dict | None): Plotting arguments or None.\n",
    "        kwargs (Any): Additional method-specific parameters.\n",
    "\n",
    "    Returns:\n",
    "        tuple[np.ndarray, pd.DataFrame]: The aligned projection and a DataFrame of internal timings.\n",
    "        \"\"\"\n",
    "    internal_timings_list = []\n",
    "    start_time_total_internal = time.perf_counter()\n",
    "\n",
    "    # Renamed plot to plot_args for clarity\n",
    "    method, x_filtered, x_sample_1, r, original_sample_1, plot_args, kwargs = args\n",
    "\n",
    "    start_time_get_method = time.perf_counter()\n",
    "    projection_method = get_method_function(method)\n",
    "    internal_timings_list.append(\n",
    "        {'operation': 'get_method_function', 'duration': time.perf_counter() - start_time_get_method})\n",
    "\n",
    "    # Combine anchor points and partition data\n",
    "    start_time_vstack = time.perf_counter()\n",
    "    x_join_sample_1 = np.vstack((x_sample_1, x_filtered))\n",
    "    internal_timings_list.append(\n",
    "        {'operation': 'vstack_data', 'duration': time.perf_counter() - start_time_vstack})\n",
    "\n",
    "    # Apply projection method\n",
    "    start_time_projection = time.perf_counter()\n",
    "    projection = projection_method(\n",
    "        x_join_sample_1, r, principal_components=False, **kwargs)\n",
    "    internal_timings_list.append(\n",
    "        {'operation': 'projection_method', 'duration': time.perf_counter() - start_time_projection})\n",
    "\n",
    "    # Visualize results\n",
    "    time_plotting_internal = 0\n",
    "    if plot_args:\n",
    "        start_time_plotting_internal = time.perf_counter()\n",
    "        plot_3D_to_2D(x_join_sample_1, projection,\n",
    "                      str(method), **plot_args)\n",
    "        time_plotting_internal = time.perf_counter() - start_time_plotting_internal\n",
    "    internal_timings_list.append(\n",
    "        {'operation': 'plotting_partition', 'duration': time_plotting_internal})\n",
    "\n",
    "    # Extract results and align using Procrustes\n",
    "    n_sample = x_sample_1.shape[0]\n",
    "    projection_sample_1 = projection[:n_sample, :]\n",
    "    projection_partition = projection[n_sample:, :]\n",
    "\n",
    "    start_time_procrustes = time.perf_counter()\n",
    "    aligned_projection = perform_procrustes(\n",
    "        projection_sample_1, original_sample_1, projection_partition, translation=False)\n",
    "    internal_timings_list.append(\n",
    "        {'operation': 'perform_procrustes', 'duration': time.perf_counter() - start_time_procrustes})\n",
    "\n",
    "    internal_timings_list.append({'operation': 'total_internal_time',\n",
    "                                 'duration': time.perf_counter() - start_time_total_internal})\n",
    "\n",
    "    internal_timings_df = pd.DataFrame(internal_timings_list)\n",
    "    return aligned_projection, internal_timings_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8613692d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def divide_conquer_benchmark(method: DRMethod,\n",
    "                                   x: np.ndarray,\n",
    "                                   l: int,\n",
    "                                   c_points: int,\n",
    "                                   r: int,\n",
    "                                   parallel: bool | None = False,\n",
    "                                   plot: dict | None = None,\n",
    "                                   # Modified return type for timings\n",
    "                                   **kwargs) -> tuple[np.ndarray, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Apply divide and conquer to a dimensionality reduction method with benchmarking.\n",
    "\n",
    "    Parameters:\n",
    "        method (DRMethod): Dimensionality reduction method to use.\n",
    "        x (np.ndarray): Input data matrix.\n",
    "        l (int): Partition size.\n",
    "        c_points (int): Number of common points.\n",
    "        r (int): Target dimensionality.\n",
    "        parallel (bool | None): Whether to run in parallel.\n",
    "        plot (dict): if not None, plot the embedding. Moreover, if not None, it must be a dict with the arguments for the plot: 'color' (np.ndarray), 'dataset_name' (str).\n",
    "        kwargs (Any): Additional method-specific parameters.\n",
    "\n",
    "    Returns:\n",
    "        projection (np.ndarray): Low-dimensional representation of the data.\n",
    "        timings_df (pd.DataFrame): Benchmark results of each part of the main function.\n",
    "    \"\"\"\n",
    "    main_timings_list = []  # List to store main timing dictionaries\n",
    "    # List to store DataFrames from each _main_divide_conquer call\n",
    "    all_internal_timings_dfs = []\n",
    "\n",
    "    start_time_total = time.perf_counter()\n",
    "\n",
    "    projection_method = get_method_function(method)\n",
    "    n_row_x = x.shape[0]\n",
    "\n",
    "    # For small datasets, apply the method directly\n",
    "    if n_row_x <= l:\n",
    "        current_timings_list = []\n",
    "        start_time_direct_projection = time.perf_counter()\n",
    "        result = projection_method(x, r, principal_components=True, **kwargs)\n",
    "        current_timings_list.append({\n",
    "            'operation': 'direct_projection',\n",
    "            'duration': time.perf_counter() - start_time_direct_projection\n",
    "        })\n",
    "        current_timings_list.append({\n",
    "            'operation': 'total_time',\n",
    "            'duration': time.perf_counter() - start_time_total\n",
    "        })\n",
    "        timings_df = pd.DataFrame(current_timings_list)\n",
    "        print(\"Main Timings (Direct Projection):\")\n",
    "        print(timings_df.to_string())\n",
    "        return result, timings_df\n",
    "\n",
    "    # Create partitions\n",
    "    start_time_partitioning = time.perf_counter()\n",
    "    idx_list = get_partitions_for_divide_conquer(n_row_x, l, c_points, r)\n",
    "    num_partitions = len(idx_list)\n",
    "    length_1 = len(idx_list[0])\n",
    "    main_timings_list.append(\n",
    "        {'operation': 'partitioning', 'duration': time.perf_counter() - start_time_partitioning})\n",
    "\n",
    "    # Process first partition\n",
    "    print(\"Projecting partition 1...\")\n",
    "    start_time_first_partition_projection = time.perf_counter()\n",
    "    x_1 = x[idx_list[0],]\n",
    "    projection_1 = projection_method(\n",
    "        x_1, r, principal_components=False, **kwargs)\n",
    "    main_timings_list.append({'operation': 'first_partition_projection',\n",
    "                             'duration': time.perf_counter() - start_time_first_partition_projection})\n",
    "\n",
    "    time_plotting_first_partition = 0\n",
    "    if plot:\n",
    "        start_time_plotting_first_partition = time.perf_counter()\n",
    "        kwargs_str = [f'{key}_{value}' for key, value in kwargs.items()]\n",
    "        results_path = os.path.join('d_and_c',\n",
    "                                    'results',\n",
    "                                    plot[\"dataset_name\"],\n",
    "                                    f'n_{n_row_x}',\n",
    "                                    f'l_{l}',\n",
    "                                    f'c_{c_points}',\n",
    "                                    str(method),\n",
    "                                    *kwargs_str,\n",
    "                                    \"d_and_c_partition_plots\"\n",
    "                                    )\n",
    "        part1_plot_path = os.path.join(results_path, 'part1')\n",
    "        os.makedirs(part1_plot_path, exist_ok=True)\n",
    "\n",
    "        fig_title = f'D&C {method} on {plot[\"dataset_name\"]} with n={n_row_x}, l={l}, c_points={c_points}, {\", \".join([f'{key}={value}' for key, value in kwargs.items(\n",
    "        )])}'\n",
    "        plot_3D_to_2D(\n",
    "            x=x_1,\n",
    "            projection=projection_1,\n",
    "            method=str(method),\n",
    "            title=fig_title + '. Part 1',\n",
    "            color=plot[\"color\"][idx_list[0]],\n",
    "            path=part1_plot_path,\n",
    "            empty=True\n",
    "        )\n",
    "        time_plotting_first_partition = time.perf_counter(\n",
    "        ) - start_time_plotting_first_partition\n",
    "    main_timings_list.append(\n",
    "        {'operation': 'plotting_first_partition', 'duration': time_plotting_first_partition})\n",
    "\n",
    "    # Sample connecting points from first partition\n",
    "    start_time_sampling = time.perf_counter()\n",
    "    sample_1_idx = np.random.choice(length_1, size=c_points, replace=False)\n",
    "    x_sample_1 = x_1[sample_1_idx, :]\n",
    "    projection_sample_1 = projection_1[sample_1_idx, :]\n",
    "    main_timings_list.append({'operation': 'sampling_connecting_points',\n",
    "                             'duration': time.perf_counter() - start_time_sampling})\n",
    "\n",
    "    # Process remaining partitions\n",
    "    start_time_build_args = time.perf_counter()\n",
    "    partition_plot_args_list = []\n",
    "    if not plot:\n",
    "        partition_plot_args_list = [None]*(num_partitions-1)\n",
    "    else:\n",
    "        # Ensure results_path is defined if plot is True (it's defined above in plotting_first_partition block)\n",
    "        for i, idx in enumerate(idx_list[1:]):\n",
    "            part_path = os.path.join(results_path, f'part{i + 2}')\n",
    "            os.makedirs(part_path, exist_ok=True)\n",
    "            partition_plot_args_list.append({\"path\": part_path,\n",
    "                                             \"color\": np.concatenate((plot[\"color\"][idx_list[0][sample_1_idx]], plot[\"color\"][idx])),\n",
    "                                             # fig_title defined above\n",
    "                                             \"title\": fig_title + f'. Part {i + 2}'\n",
    "                                             })\n",
    "    args_list = [\n",
    "        (\n",
    "            method,\n",
    "            x[idx, :],\n",
    "            x_sample_1,\n",
    "            r,\n",
    "            projection_sample_1,\n",
    "            # Handle case of single partition after first\n",
    "            partition_plot_args_list[i] if num_partitions > 1 else None,\n",
    "            kwargs.copy()\n",
    "        )\n",
    "        for i, idx in enumerate(idx_list[1:])\n",
    "    ]\n",
    "    main_timings_list.append({'operation': 'build_remaining_partitions_args',\n",
    "                             'duration': time.perf_counter() - start_time_build_args})\n",
    "\n",
    "    start_time_remaining_partitions = time.perf_counter()\n",
    "    projections = [None] * (num_partitions - 1)\n",
    "    if parallel:\n",
    "        print(\"Projecting remaining partitions in parallel...\")\n",
    "        with ProcessPoolExecutor(max_workers=os.cpu_count()) as executor:\n",
    "            futures = [executor.submit(_main_divide_conquer_benchmark, arg_set)\n",
    "                       for arg_set in args_list]\n",
    "            for i, future in enumerate(futures):\n",
    "                proj_result, internal_df = future.result()\n",
    "                projections[i] = proj_result\n",
    "                all_internal_timings_dfs.append(internal_df)\n",
    "    else:\n",
    "        for i in range(num_partitions-1):\n",
    "            print(f\"Projecting partition {i + 2}...\")\n",
    "            proj_result, internal_df = _main_divide_conquer_benchmark(args_list[i])\n",
    "            projections[i] = proj_result\n",
    "            all_internal_timings_dfs.append(internal_df)\n",
    "\n",
    "    main_timings_list.append({'operation': 'remaining_partitions_processing',\n",
    "                             'duration': time.perf_counter() - start_time_remaining_partitions})\n",
    "\n",
    "    # Combine all projections\n",
    "    start_time_combine_projections = time.perf_counter()\n",
    "    all_projections_list = [projection_1] + \\\n",
    "        (projections if num_partitions > 1 else [])\n",
    "    combined_projection = np.vstack(all_projections_list)\n",
    "    main_timings_list.append({'operation': 'combine_projections',\n",
    "                             'duration': time.perf_counter() - start_time_combine_projections})\n",
    "\n",
    "    # Reorder rows to match original data order\n",
    "    start_time_reorder = time.perf_counter()\n",
    "    order_idx = np.concatenate(idx_list)\n",
    "    order = np.argsort(order_idx)\n",
    "    combined_projection = combined_projection[order, :]\n",
    "    main_timings_list.append(\n",
    "        {'operation': 'reorder_rows', 'duration': time.perf_counter() - start_time_reorder})\n",
    "\n",
    "    # Center and rotate for maximum variance\n",
    "    start_time_center_rotate = time.perf_counter()\n",
    "    combined_projection_mean = np.mean(combined_projection, axis=0)\n",
    "    centered_projection = combined_projection - combined_projection_mean\n",
    "    cov_matrix = np.cov(centered_projection, rowvar=False)\n",
    "    eigenvals, eigenvecs = np.linalg.eigh(cov_matrix)\n",
    "    idx_sort = np.argsort(eigenvals)[::-1]\n",
    "    sorted_eigenvecs = eigenvecs[:, idx_sort]\n",
    "    final_projection = centered_projection @ sorted_eigenvecs\n",
    "    main_timings_list.append({'operation': 'center_rotate',\n",
    "                             'duration': time.perf_counter() - start_time_center_rotate})\n",
    "\n",
    "    main_timings_list.append(\n",
    "        {'operation': 'total_time', 'duration': time.perf_counter() - start_time_total})\n",
    "\n",
    "    main_timings_df = pd.DataFrame(main_timings_list)\n",
    "    print(\"Main Timings:\")\n",
    "    print(main_timings_df.to_string())\n",
    "\n",
    "    if all_internal_timings_dfs:\n",
    "        print(\"\\nInternal Timings per _main_divide_conquer call:\")\n",
    "        for i, internal_df in enumerate(all_internal_timings_dfs):\n",
    "            print(f\"\\n  Call {i+1}:\")\n",
    "            print(internal_df.to_string())\n",
    "\n",
    "    return final_projection, main_timings_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa1946a",
   "metadata": {},
   "source": [
    "Load MNIST 5000-points subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dafc819",
   "metadata": {},
   "outputs": [],
   "source": [
    "MNIST_path = os.path.join(project_root, 'd_and_c', 'MNIST_5000.pkl')\n",
    "with open(MNIST_path, \"rb\") as f:\n",
    "    bare_data = pickle.load(f)\n",
    "    pixels = bare_data[\"pixels\"]\n",
    "    target = bare_data[\"target\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013d4439",
   "metadata": {},
   "source": [
    "Apply D&C SMACOF to MNIST subset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aecd151",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Projecting partition 1...\n",
      "Projecting partition 2...\n",
      "Projecting partition 3...\n",
      "Projecting partition 4...\n",
      "Projecting partition 5...\n",
      "Projecting partition 6...\n",
      "Main Timings:\n",
      "                         operation   duration\n",
      "0                     partitioning   0.000210\n",
      "1       first_partition_projection   7.550072\n",
      "2         plotting_first_partition   0.000000\n",
      "3       sampling_connecting_points   0.000219\n",
      "4  build_remaining_partitions_args   0.006455\n",
      "5  remaining_partitions_processing  30.329799\n",
      "6              combine_projections   0.000026\n",
      "7                     reorder_rows   0.000387\n",
      "8                    center_rotate   0.000334\n",
      "9                       total_time  37.887548\n",
      "\n",
      "Internal Timings per _main_divide_conquer call:\n",
      "\n",
      "  Call 1:\n",
      "             operation  duration\n",
      "0  get_method_function  0.000007\n",
      "1          vstack_data  0.001079\n",
      "2    projection_method  6.073384\n",
      "3   plotting_partition  0.000000\n",
      "4   perform_procrustes  0.000085\n",
      "5  total_internal_time  6.074576\n",
      "\n",
      "  Call 2:\n",
      "             operation  duration\n",
      "0  get_method_function  0.000006\n",
      "1          vstack_data  0.000803\n",
      "2    projection_method  6.002320\n",
      "3   plotting_partition  0.000000\n",
      "4   perform_procrustes  0.000080\n",
      "5  total_internal_time  6.003215\n",
      "\n",
      "  Call 3:\n",
      "             operation  duration\n",
      "0  get_method_function  0.000007\n",
      "1          vstack_data  0.000773\n",
      "2    projection_method  5.920120\n",
      "3   plotting_partition  0.000000\n",
      "4   perform_procrustes  0.000079\n",
      "5  total_internal_time  5.920985\n",
      "\n",
      "  Call 4:\n",
      "             operation  duration\n",
      "0  get_method_function  0.000005\n",
      "1          vstack_data  0.000888\n",
      "2    projection_method  6.136164\n",
      "3   plotting_partition  0.000000\n",
      "4   perform_procrustes  0.000079\n",
      "5  total_internal_time  6.137142\n",
      "\n",
      "  Call 5:\n",
      "             operation  duration\n",
      "0  get_method_function  0.000005\n",
      "1          vstack_data  0.000826\n",
      "2    projection_method  6.190353\n",
      "3   plotting_partition  0.000000\n",
      "4   perform_procrustes  0.000097\n",
      "5  total_internal_time  6.191287\n"
     ]
    }
   ],
   "source": [
    "l, c_points = 1000, 100\n",
    "embedding, timings = divide_conquer_benchmark(\n",
    "    DRMethod.SMACOF, pixels, l=l, c_points=c_points, r=2, verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96a8ab2c",
   "metadata": {},
   "source": [
    "There is no need to repeat the benchmark many times and aggregate results, because they are clear. The bottleneck of d_and_c is the dimensionality reduction tecnique used."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
