@article{
	paradis2021,
	author = {Paradis, Emmanuel},
	year = {2021},
	volume = {},
	pages = {Published on-line 05 June 2021},
	title = {Reduced multidimensional scaling},
	journal = {Computational Statistics},
	doi = {10.1007/s00180-021-01116-0}
}

@inproceedings{
	metric_map,
	author = {Wang, Jason Tsong-Li and Wang, Xiong and Lin, King-Ip and Shasha, Dennis and Shapiro, Bruce A. and Zhang, Kaizhong},
	title = {Evaluating a Class of Distance-Mapping Algorithms for Data Mining and Clustering},
	year = {1999},
	isbn = {1581131437},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/312129.312264},
	doi = {10.1145/312129.312264},
	booktitle = {Proceedings of the Fifth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
	pages = {307–311},
	numpages = {5},
	location = {San Diego, California, USA},
	series = {KDD '99}
}

@inproceedings{
	Yang06afast,
	author = {Tynia Yang and Jinze Liu and Leonard McMillan and Wei Wang},
	title = {A fast approximation to multidimensional scaling},
	booktitle = {Proceedings of the ECCV Workshop on Computation Intensive Methods for Computer Vision (CIMCV)},
	year = {2006}
}

@book{
	BorgGroenen2005,
	author = {Borg, I. and Groenen, P.},
	biburl = {https://www.bibsonomy.org/bibtex/2b9360235f054e3b2ff0e4b4a0c63b4eb/tmalsburg},
	publisher = {Springer},
	title = {Modern Multidimensional Scaling: Theory and Applications},
	year = {2005}
}

@book{
	GowerHand:1995,
	author = {Gower, John C and Hand, David J},
	publisher = {CRC Press},
	title = {Biplots},
	volume = {54},
	year = {1995}
}

@book{
	krzanowski2000principles,
	 author = {Krzanowski, Wojtek},
	 edition = {Revised},
	 publisher = {OUP Oxford},
	 series = {Oxford Statistical Science Series},
	 subtitle = {A User's Perspective},
	 title = {Principles of Multivariate Analysis},
	 volume = {23},
	 year = {2000}
}

@book{
	johnson2002applied,
	author = {Johnson, Richard Arnold and Wichern, Dean W.},
	edition = {5th},
	publisher = {Prentice Hall},
	title = {Applied Multivariate Statistical Analysis},
	year = {2002}
}

@book{
	trefethen97,
	added-at = {2010-09-19T02:35:23.000+0200},
	author = {Trefethen, Lloyd N. and Bau, David},
	biburl = {https://www.bibsonomy.org/bibtex/2e45a2ed5ccc6dc12721cde613217c222/ytyoun},
	interhash = {1e7e7a44cbff3092be50a71fe056c8ec},
	intrahash = {e45a2ed5ccc6dc12721cde613217c222},
	isbn = {0898713617},
	keywords = {characteristic eigenvalues linear.algebra matrix numerical numerical.analysis polynomial secular.equation textbook},
	publisher={Society for Industrial and Applied Mathematics},
	timestamp = {2017-11-25T07:18:16.000+0100},
	title = {Numerical Linear Algebra},
	year = {1997}
}

@manual{
	pdistPackage,
	author = {Jeffrey Wong},
	note = {R package version 1.2},
	title = {pdist: Partitioned Distance Function},
    url = {https://CRAN.R-project.org/package=pdist},
    year = {2013}
}

@manual{
	Rprogram,
	address = {Vienna, Austria},
	author = {{R Core Team}},
	organization = {R Foundation for Statistical Computing},
	title = {R: A Language and Environment for Statistical Computing},
	url = {https://www.R-project.org/},
	year = {2020}
}

@INPROCEEDINGS{
	emnist,
	author={Cohen, Gregory and Afshar, Saeed and Tapson, Jonathan and van Schaik, André},
	booktitle={2017 International Joint Conference on Neural Networks (IJCNN)}, 
	title={EMNIST: Extending MNIST to handwritten letters}, 
	year={2017},
	volume={},
	number={},
	pages={2921-2926},
	doi={10.1109/IJCNN.2017.7966217}}

@misc{
	nist_special,
	author = {Patrick Grother},
	title = {{NIST} Special Database 19. {NIST} Handprinted Forms and Characters Database},
	year = {1970},
	publisher = {World Wide Web-Internet and Web Information Systems},
	language = {en},
}

@misc{
	mnist,
	added-at = {2010-06-28T21:16:30.000+0200},
	author = {LeCun, Yann and Cortes, Corinna},
	biburl = {https://www.bibsonomy.org/bibtex/2935bad99fa1f65e03c25b315aa3c1032/mhwombat},
	groups = {public},
	howpublished = {http://yann.lecun.com/exdb/mnist/},
	interhash = {21b9d0558bd66279df9452562df6e6f3},
	intrahash = {935bad99fa1f65e03c25b315aa3c1032},
	keywords = {MSc _checked character_recognition mnist network neural},
	lastchecked = {2016-01-14 14:24:11},
	timestamp = {2016-07-12T19:25:30.000+0200},
	title = {{MNIST} handwritten digit database},
	url = {http://yann.lecun.com/exdb/mnist/},
	username = {mhwombat},
	year = 2010
}

@article{
	bentley1980general,
	title = {A general method for solving divide-and-conquer recurrences},
	author ={Bentley, Jon Louis and Haken, Dorothea and Saxe, James B},
	journal = {ACM SIGACT News},
	volume = {12},
	number = {3},
	pages = {36--44},
	year = {1980},
	publisher = {ACM New York, NY, USA}
}

@article{
	kristof,
	title = {A theorem on the trace of certain matrix products and some applications},
	journal = {Journal of Mathematical Psychology},
	volume = {7},
	number = {3},
	pages = {515-530},
	year = {1970},
	issn = {0022-2496},
	doi = {https://doi.org/10.1016/0022-2496(70)90037-4},
	url = {https://www.sciencedirect.com/science/article/pii/0022249670900374},
	author = {Walter Kristof},
	abstract = {A theorem giving attainable upper and lower limits for the trace of certain products of real matrices is established. These products are of the form X1Γ1X2Γ2 … XnΓn with orthogonal matrices Xi and diagonal matrices Γi where the matrices Xi are allowed to vary independently and unrestrictedly. The proof makes use of two lemmas. The theorem may find application in psychometrics when the trace of matrices is involved. Several examples taken from this area are appended by way of illustration.}
}

@misc{
	Pachon_Garcia_2019, 
	author={Pach\'on-Garc\'{\i}a, Cristian}, 
	title={Multidimensional scaling for Big Data}, 
    year={2019},
	howpublished ={http://hdl.handle.net/2117/127318}, 
	organization={UPC, Facultat de Matem\`atiques i Estad\'{\i}stica, Master in Statistics and Operations Research}
}

@article{
	Gower:1968,
	author={Gower, John C},
	title={Adding a point to vector diagrams in multivariate analysis},
	year={1968},
	journal= {Biometrika},
	volume= 55,
	number= 3,
	pages={582-–585}
}

@article{
	Paradis:2018,
	author = {Emmanuel Paradis},
	title = {Multidimensional Scaling With Very Large Datasets},
	journal = {Journal of Computational and Graphical Statistics},
	volume = {27},
	number = {4},
	pages = {935--939},
	year  = {2018},
	publisher = {Taylor & Francis},
	doi = {10.1080/10618600.2018.1470001},
	URL = {https://doi.org/10.1080/10618600.2018.1470001},
	eprint = {https://doi.org/10.1080/10618600.2018.1470001}
}

@article{
	Mardia:1978,
	author = {   K.V.   Mardia },
	title = {Some properties of clasical multi-dimesional scaling},
	journal = {Communications in Statistics - Theory and Methods},
	volume = {7},
	number = {13},
	pages = {1233-1241},
	year  = {1978},
	publisher = {Taylor & Francis},
	doi = {10.1080/03610927808827707},
	URL = {https://doi.org/10.1080/03610927808827707},
	eprint = {https://doi.org/10.1080/03610927808827707}
}

@book{
	MardiaKentBibby:1979,
	title={Multivariate analysis},
	author={Mardia, KV and Kent, M and Bibby, JM },
	series={Probability and Mathematical Statistics}, 
	publisher={Academic Press},
	year={1979}
}

@Manual{
	svd_package:2022,
	title = {svd: Interfaces to Various State-of-Art SVD and Eigensolvers},
	author = {Anton Korobeynikov and Rasmus Munk Larsen and Lawrence Berkeley National Laboratory},
	year = {2022},
	note = {R package version 0.5.2},
	url = {https://CRAN.R-project.org/package=svd},
}

@Article{
	RcppEigen:2013,
	title = {Fast and Elegant Numerical Linear Algebra Using the {RcppEigen} Package},
	author = {Douglas Bates and Dirk Eddelbuettel},
	journal = {Journal of Statistical Software},
	year = {2013},
	volume = {52},
	number = {5},
	pages = {1--24},
	doi = {10.18637/jss.v052.i05},
}

@techreport{
	LMDS:2004,
	title={Sparse multidimensional scaling using landmark points},
	author={De Silva, Vin and Tenenbaum, Joshua B},
	year={2004},
	institution={Technical Report, Stanford University}
}

@article{
	LMDS_ensamble:2009,
	title={Landmark MDS ensemble},
	author={Lee, Seunghak and Choi, Seungjin},
	journal={Pattern recognition},
	volume={42},
	number={9},
	pages={2045--2053},
	year={2009},
	publisher={Elsevier}
}

@article{
	torgerson1952multidimensional,
	title={Multidimensional scaling: I. Theory and method},
	author={Torgerson, Warren S},
	journal={Psychometrika},
	volume={17},
	number={4},
	pages={401--419},
	year={1952},
	publisher={Springer}
}

@article{
	gower1966some,
	title={Some distance properties of latent root and vector methods used in multivariate analysis},
	author={Gower, John C},
	journal={Biometrika},
	volume={53},
	number={3-4},
	pages={325--338},
	year={1966},
	publisher={Oxford University Press}
}

@article{
	saeed2018survey,
	title={A survey on multidimensional scaling},
	author={Saeed, Nasir and Nam, Haewoon and Haq, Mian Imtiaz Ul and Muhammad Saqib, Dost Bhatti},
	journal={ACM Computing Surveys (CSUR)},
	volume={51},
	number={3},
	pages={1--25},
	year={2018},
	publisher={ACM New York, NY, USA}
}

@article{
	Shepard:1962:MDS_1,
	title={The analysis of proximities: {M}ultidimensional scaling with an unknown distance function. I.},
	author={Shepard, Roger N},
	journal={Psychometrika},
	volume={27},
	number={2},
	pages={125--140},
	year={1962},
	publisher={Springer}
}

@article{
	Shepard:1962:MDS_2,
	title={The analysis of proximities: {M}ultidimensional scaling with an unknown distance function. II},
	author={Shepard, Roger N},
	journal={Psychometrika},
	volume={27},
	number={3},
	pages={219--246},
	year={1962},
	publisher={Springer}
}

@article{
	Kruskal:1964:a,
	title={Multidimensional scaling by optimizing goodness of fit to a nonmetric hypothesis},
	author={Kruskal, Joseph B},
	journal={Psychometrika},
	volume={29},
	number={1},
	pages={1--27},
	year={1964},
	publisher={Springer}
}

@article{
	Kruskal:1964:b,
	title={Nonmetric multidimensional scaling: {A} numerical method},
	author={Kruskal, Joseph B},
	journal={Psychometrika},
	volume={29},
	number={2},
	pages={115--129},
	year={1964},
	publisher={Springer}
}

@InProceedings{
	Platt:2005,
	title = 	 {FastMap, MetricMap, and Landmark MDS are all Nystr\"om Algorithms},
	author =       {Platt, John},
	booktitle = 	 {Proceedings of the Tenth International Workshop on Artificial Intelligence and Statistics},
	pages = 	 {261--268},
	year = 	 {2005},
	editor = 	 {Cowell, Robert G. and Ghahramani, Zoubin},
	volume = 	 {R5},
	series = 	 {Proceedings of Machine Learning Research},
	month = 	 {06--08 Jan},
	publisher =    {PMLR},
	pdf = 	 {http://proceedings.mlr.press/r5/platt05a/platt05a.pdf},
	url = 	 {https://proceedings.mlr.press/r5/platt05a.html},
	note =         {Reissued by PMLR on 30 March 2021.}
}


@inproceedings{
	fastmap,
	author = {Faloutsos, Christos and Lin, King-Ip},
	title = {FastMap: A Fast Algorithm for Indexing, Data-Mining and Visualization of Traditional and Multimedia Datasets},
	year = {1995},
	isbn = {0897917316},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	url = {https://doi.org/10.1145/223784.223812},
	doi = {10.1145/223784.223812},
	abstract = {A very promising idea for fast searching in traditional and multimedia databases is to map objects into points in k-d space, using k feature-extraction functions, provided by a domain expert [25]. Thus, we can subsequently use highly fine-tuned spatial access methods (SAMs), to answer several types of queries, including the 'Query By Example' type (which translates to a range query); the 'all pairs' query (which translates to a spatial join [8]); the nearest-neighbor or best-match query, etc.However, designing feature extraction functions can be hard. It is relatively easier for a domain expert to assess the similarity/distance of two objects. Given only the distance information though, it is not obvious how to map objects into points.This is exactly the topic of this paper. We describe a fast algorithm to map objects into points in some k-dimensional space (k is user-defined), such that the dis-similarities are preserved. There are two benefits from this mapping: (a) efficient retrieval, in conjunction with a SAM, as discussed before and (b) visualization and data-mining: the objects can now be plotted as points in 2-d or 3-d space, revealing potential clusters, correlations among attributes and other regularities that data-mining is looking for.We introduce an older method from pattern recognition, namely, Multi-Dimensional Scaling (MDS) [51]; although unsuitable for indexing, we use it as yardstick for our method. Then, we propose a much faster algorithm to solve the problem in hand, while in addition it allows for indexing. Experiments on real and synthetic data indeed show that the proposed algorithm is significantly faster than MDS, (being linear, as opposed to quadratic, on the database size N), while it manages to preserve distances and the overall structure of the data-set.},
	booktitle = {Proceedings of the 1995 ACM SIGMOD International Conference on Management of Data},
	pages = {163–174},
	numpages = {12},
	location = {San Jose, California, USA},
	series = {SIGMOD '95}
}

@InProceedings{
	pivot_MDS:2007,
	author="Brandes, Ulrik
	and Pich, Christian",
	editor="Kaufmann, Michael
	and Wagner, Dorothea",
	title="Eigensolver Methods for Progressive Multidimensional Scaling of Large Data",
	booktitle="Graph Drawing",
	year="2007",
	publisher="Springer Berlin Heidelberg",
	address="Berlin, Heidelberg",
	pages="42--53",
	abstract="We present a novel sampling-based approximation technique for classical multidimensional scaling that yields an extremely fast layout algorithm suitable even for very large graphs. It produces layouts that compare favorably with other methods for drawing large graphs, and it is among the fastest methods available. In addition, our approach allows for progressive computation, i.e. a rough approximation of the layout can be produced even faster, and then be refined until satisfaction.",
	isbn="978-3-540-70904-6"
}

@Article{
	pivot_mds_R,
	author = {{David Schoch}},
	title = {graphlayouts: Layout algorithms for network visualizations
	in R},
	year = {2023},
	publisher = {The Open Journal},
	volume = {8},
	number = {84},
	pages = {5238},
	journal = {Journal of Open Source Software},
	doi = {10.21105/joss.05238},
	url = {https://doi.org/10.21105/joss.05238},
}

@Manual{
	microbenchmark,    
	title = {microbenchmark: Accurate Timing Functions}, 
	author = {Olaf Mersmann}, 
	year = {2023}, 
	note = {R package version 1.4.10},
	url = {https://CRAN.R-project.org/package=microbenchmark}
}

@Article{
	Rdimtools,
	title = {{Rdimtools}: An {R} Package for Dimension Reduction and Intrinsic Dimension Estimation},
	author = {Kisung You and Dennis Shung},
	journal = {Software Impacts},
	year = {2022},
	volume = {14},
	issn = {26659638},
	pages = {100414},
	doi = {10.1016/j.simpa.2022.100414}
}

@article{
	Lanczos_restart,
	author = {Wu, Kesheng and Simon, Horst},
	title = {Thick-Restart Lanczos Method for Large Symmetric Eigenvalue Problems},
	journal = {SIAM Journal on Matrix Analysis and Applications},
	volume = {22},
	number = {2},
	pages = {602-616},
	year = {2000},
	doi = {10.1137/S0895479898334605},
	URL = { https://doi.org/10.1137/S0895479898334605},
	eprint = {https://doi.org/10.1137/S0895479898334605},
	abstract = { In this paper, we propose a restarted variant of the Lanczos method for symmetric eigenvalue problems named the thick-restart Lanczos method. This new variant is able to retain an arbitrary number of Ritz vectors from the previous iterations with a minimal restarting cost. Since it restarts with Ritz vectors, it is simpler than similar methods, such as the implicitly restarted Lanczos method. We carefully examine the effects of the floating-point round-off errors on stability of the new algorithm and present an implementation of the partial reorthogonalization scheme that guarantees accurate Ritz values with a minimal amount of reorthogonalization. We also show a number of heuristics on deciding which Ritz pairs to save during restart in order to maximize the overall performance of the thick-restart Lanczos method. }
}

@article{
	Lanczos_adaptive,
	author = {Yamazaki, Ichitaro and Bai, Zhaojun and Simon, Horst and Wang, Lin-Wang and Wu, Kesheng},
	title = {Adaptive Projection Subspace Dimension for the Thick-Restart Lanczos Method},
	year = {2010},
	issue_date = {September 2010},
	publisher = {Association for Computing Machinery},
	address = {New York, NY, USA},
	volume = {37},
	number = {3},
	issn = {0098-3500},
	url = {https://doi.org/10.1145/1824801.1824805},
	doi = {10.1145/1824801.1824805},
	abstract = {The Thick-Restart Lanczos (TRLan) method is an effective method for solving large-scale Hermitian eigenvalue problems. The performance of the method strongly depends on the dimension of the projection subspace used at each restart. In this article, we propose an objective function to quantify the effectiveness of the selection of subspace dimension, and then introduce an adaptive scheme to dynamically select the dimension to optimize the performance. We have developed an open-source software package a--TRLan to include this adaptive scheme in the TRLan method. When applied to calculate the electronic structure of quantum dots, a--TRLan runs up to 2.3x faster than a state-of-the-art preconditioned conjugate gradient eigensolver.},
	journal = {ACM Trans. Math. Softw.},
	month = {sep},
	articleno = {27},
	numpages = {18},
	keywords = {electronic structure calculation, thick-restart, Lanczos, Adaptive subspace dimension}
}
